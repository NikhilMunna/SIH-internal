{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "regression_auto_kalman_lstm.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbuKjPvV2az",
        "colab_type": "text"
      },
      "source": [
        "# Predictive Maintenance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBK9LHSeV2a5",
        "colab_type": "text"
      },
      "source": [
        "## Dataset 1 - Regression (RUL) using Autoencoder + Kalman + LSTM\n",
        "\n",
        "Here, we fit an autoencoder on the train set which learns to regenerate the train set. By using the activations of some intermediate layer of the autoencoder, we get an efficient representation of the original noisy train data. This representation of the original data can be used to train the LSTM model for predicting RUL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIjbBmkTV2a-",
        "colab_type": "code",
        "outputId": "06a05df8-21dc-4502-8b30-b4cc91d2e7e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "!pip install pykalman"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.6/dist-packages (0.9.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqgbqEgvdUPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWDr0Pl5dUJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNGMNx5EdUGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4xUyVhGV2bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setting seed for reproducability\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQHs35MrV2bW",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess Train and Test Data using Kalman Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udbaLAHWV2ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read training data \n",
        "train_df = pd.read_csv('train_01.txt', sep=\" \", header=None)\n",
        "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHcMuKyNV2bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pykalman import KalmanFilter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A57k1_MV2bs",
        "colab_type": "code",
        "outputId": "a0bf67cf-1818-49ca-8414-ed4b852d085f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
              "0   1      1   -0.0007   -0.0004     100.0  ...  392  2388  100.0  39.06  23.4190\n",
              "1   1      2    0.0019   -0.0003     100.0  ...  392  2388  100.0  39.00  23.4236\n",
              "2   1      3   -0.0043    0.0003     100.0  ...  390  2388  100.0  38.95  23.3442\n",
              "3   1      4    0.0007    0.0000     100.0  ...  392  2388  100.0  38.88  23.3739\n",
              "4   1      5   -0.0019   -0.0002     100.0  ...  393  2388  100.0  38.90  23.4044\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8gKd934V2by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.columns\n",
        "cols = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "       's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "       's15', 's16', 's17', 's18', 's19', 's20', 's21']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWoPxEbYV2b4",
        "colab_type": "code",
        "outputId": "1d48265b-869d-4899-9615-fc19fcb6a583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.columns[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'setting1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciyqr-tHV2cA",
        "colab_type": "code",
        "outputId": "705af5cd-13b4-4ef4-b995-57e315c57355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "for cols in train_df.columns:\n",
        "    if cols == 'id':\n",
        "        continue;\n",
        "    if cols == 'cycle':\n",
        "        continue;\n",
        "    else:\n",
        "        print(cols)\n",
        "        kf = KalmanFilter(transition_matrices = [1],\n",
        "                      observation_matrices = [1],\n",
        "                      initial_state_mean = train_df[cols].values[0],\n",
        "                      initial_state_covariance = 1,\n",
        "                      observation_covariance=1,\n",
        "                      transition_covariance=.01)\n",
        "        state_means,_ = kf.filter(train_df[cols].values)\n",
        "        train_df[cols] = state_means.flatten()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting1\n",
            "setting2\n",
            "setting3\n",
            "s1\n",
            "s2\n",
            "s3\n",
            "s4\n",
            "s5\n",
            "s6\n",
            "s7\n",
            "s8\n",
            "s9\n",
            "s10\n",
            "s11\n",
            "s12\n",
            "s13\n",
            "s14\n",
            "s15\n",
            "s16\n",
            "s17\n",
            "s18\n",
            "s19\n",
            "s20\n",
            "s21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhHU1UJbV2cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read test data\n",
        "test_df = pd.read_csv('test_01.txt', sep=\" \", header=None)\n",
        "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgR4t9CRV2cO",
        "colab_type": "code",
        "outputId": "87bbc728-867a-4a43-a584-1597e71ba010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "for cols in test_df.columns:\n",
        "    if cols == 'id':\n",
        "        continue;\n",
        "    if cols == 'cycle':\n",
        "        continue;\n",
        "    else:\n",
        "        print(cols)\n",
        "        kf = KalmanFilter(transition_matrices = [1],\n",
        "                      observation_matrices = [1],\n",
        "                      initial_state_mean = test_df[cols].values[0],\n",
        "                      initial_state_covariance = 1,\n",
        "                      observation_covariance=1,\n",
        "                      transition_covariance=.01)\n",
        "        state_means,_ = kf.filter(test_df[cols].values)\n",
        "        test_df[cols] = state_means.flatten()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setting1\n",
            "setting2\n",
            "setting3\n",
            "s1\n",
            "s2\n",
            "s3\n",
            "s4\n",
            "s5\n",
            "s6\n",
            "s7\n",
            "s8\n",
            "s9\n",
            "s10\n",
            "s11\n",
            "s12\n",
            "s13\n",
            "s14\n",
            "s15\n",
            "s16\n",
            "s17\n",
            "s18\n",
            "s19\n",
            "s20\n",
            "s21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAGq5cXmV2cU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read ground truth data\n",
        "truth_df = pd.read_csv('truth_01.txt', sep=\" \", header=None)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKtygN-2V2ca",
        "colab_type": "code",
        "outputId": "72f2fd1e-8d3c-4fe4-8155-bc3063a19683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "train_df = train_df.sort_values(['id','cycle'])\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.000400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.820000</td>\n",
              "      <td>1589.700000</td>\n",
              "      <td>1400.600000</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.360000</td>\n",
              "      <td>2388.060000</td>\n",
              "      <td>9046.190000</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.470000</td>\n",
              "      <td>521.660000</td>\n",
              "      <td>2388.020000</td>\n",
              "      <td>8138.620000</td>\n",
              "      <td>8.419500</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.060000</td>\n",
              "      <td>23.419000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.931457</td>\n",
              "      <td>1590.416026</td>\n",
              "      <td>1401.457881</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.153974</td>\n",
              "      <td>2388.053245</td>\n",
              "      <td>9045.473974</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.476755</td>\n",
              "      <td>521.869404</td>\n",
              "      <td>2388.036887</td>\n",
              "      <td>8136.211854</td>\n",
              "      <td>8.423654</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.039735</td>\n",
              "      <td>23.420554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000977</td>\n",
              "      <td>-0.000194</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.039450</td>\n",
              "      <td>1589.790059</td>\n",
              "      <td>1402.165407</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.181331</td>\n",
              "      <td>2388.060148</td>\n",
              "      <td>9047.400370</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.423408</td>\n",
              "      <td>522.011470</td>\n",
              "      <td>2388.035110</td>\n",
              "      <td>8135.442471</td>\n",
              "      <td>8.422144</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.483957</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.016581</td>\n",
              "      <td>23.400853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.000623</td>\n",
              "      <td>-0.000153</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.105091</td>\n",
              "      <td>1588.310457</td>\n",
              "      <td>1402.102967</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.238119</td>\n",
              "      <td>2388.070686</td>\n",
              "      <td>9047.839942</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.361390</td>\n",
              "      <td>522.190824</td>\n",
              "      <td>2388.044599</td>\n",
              "      <td>8135.101643</td>\n",
              "      <td>8.410742</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.593033</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.987712</td>\n",
              "      <td>23.395156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.000854</td>\n",
              "      <td>-0.000162</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.153105</td>\n",
              "      <td>1587.320764</td>\n",
              "      <td>1402.849168</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.194961</td>\n",
              "      <td>2388.068749</td>\n",
              "      <td>9049.164870</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.346638</td>\n",
              "      <td>522.190674</td>\n",
              "      <td>2388.043765</td>\n",
              "      <td>8134.865724</td>\n",
              "      <td>8.414123</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.848042</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.971815</td>\n",
              "      <td>23.396831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...     s18    s19        s20        s21\n",
              "0   1      1 -0.000700 -0.000400  ...  2388.0  100.0  39.060000  23.419000\n",
              "1   1      2  0.000178 -0.000366  ...  2388.0  100.0  39.039735  23.420554\n",
              "2   1      3 -0.000977 -0.000194  ...  2388.0  100.0  39.016581  23.400853\n",
              "3   1      4 -0.000623 -0.000153  ...  2388.0  100.0  38.987712  23.395156\n",
              "4   1      5 -0.000854 -0.000162  ...  2388.0  100.0  38.971815  23.396831\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8KWzp-nV2cg",
        "colab_type": "text"
      },
      "source": [
        "## Generate True Labels (RUL) for Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHNspPvZV2ci",
        "colab_type": "code",
        "outputId": "15b2ba9a-5909-4bca-b91a-47bda825b2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "# Data Labeling - generate column RUL\n",
        "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "train_df = train_df.merge(rul, on=['id'], how='left')\n",
        "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
        "train_df.drop('max', axis=1, inplace=True)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.000400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.820000</td>\n",
              "      <td>1589.700000</td>\n",
              "      <td>1400.600000</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.360000</td>\n",
              "      <td>2388.060000</td>\n",
              "      <td>9046.190000</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.470000</td>\n",
              "      <td>521.660000</td>\n",
              "      <td>2388.020000</td>\n",
              "      <td>8138.620000</td>\n",
              "      <td>8.419500</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.060000</td>\n",
              "      <td>23.419000</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.931457</td>\n",
              "      <td>1590.416026</td>\n",
              "      <td>1401.457881</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.153974</td>\n",
              "      <td>2388.053245</td>\n",
              "      <td>9045.473974</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.476755</td>\n",
              "      <td>521.869404</td>\n",
              "      <td>2388.036887</td>\n",
              "      <td>8136.211854</td>\n",
              "      <td>8.423654</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.039735</td>\n",
              "      <td>23.420554</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000977</td>\n",
              "      <td>-0.000194</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.039450</td>\n",
              "      <td>1589.790059</td>\n",
              "      <td>1402.165407</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.181331</td>\n",
              "      <td>2388.060148</td>\n",
              "      <td>9047.400370</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.423408</td>\n",
              "      <td>522.011470</td>\n",
              "      <td>2388.035110</td>\n",
              "      <td>8135.442471</td>\n",
              "      <td>8.422144</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.483957</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.016581</td>\n",
              "      <td>23.400853</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.000623</td>\n",
              "      <td>-0.000153</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.105091</td>\n",
              "      <td>1588.310457</td>\n",
              "      <td>1402.102967</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.238119</td>\n",
              "      <td>2388.070686</td>\n",
              "      <td>9047.839942</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.361390</td>\n",
              "      <td>522.190824</td>\n",
              "      <td>2388.044599</td>\n",
              "      <td>8135.101643</td>\n",
              "      <td>8.410742</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.593033</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.987712</td>\n",
              "      <td>23.395156</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.000854</td>\n",
              "      <td>-0.000162</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.153105</td>\n",
              "      <td>1587.320764</td>\n",
              "      <td>1402.849168</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.194961</td>\n",
              "      <td>2388.068749</td>\n",
              "      <td>9049.164870</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.346638</td>\n",
              "      <td>522.190674</td>\n",
              "      <td>2388.043765</td>\n",
              "      <td>8134.865724</td>\n",
              "      <td>8.414123</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.848042</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.971815</td>\n",
              "      <td>23.396831</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...    s19        s20        s21  RUL\n",
              "0   1      1 -0.000700 -0.000400  ...  100.0  39.060000  23.419000  191\n",
              "1   1      2  0.000178 -0.000366  ...  100.0  39.039735  23.420554  190\n",
              "2   1      3 -0.000977 -0.000194  ...  100.0  39.016581  23.400853  189\n",
              "3   1      4 -0.000623 -0.000153  ...  100.0  38.987712  23.395156  188\n",
              "4   1      5 -0.000854 -0.000162  ...  100.0  38.971815  23.396831  187\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX1xFyKZV2cn",
        "colab_type": "code",
        "outputId": "cd7b947c-c3ed-4a62-c2ac-37725460088d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "# generate label columns for training data\n",
        "w1 = 30\n",
        "w0 = 15\n",
        "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
        "train_df['label2'] = train_df['label1']\n",
        "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>RUL</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.000700</td>\n",
              "      <td>-0.000400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.820000</td>\n",
              "      <td>1589.700000</td>\n",
              "      <td>1400.600000</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.360000</td>\n",
              "      <td>2388.060000</td>\n",
              "      <td>9046.190000</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.470000</td>\n",
              "      <td>521.660000</td>\n",
              "      <td>2388.020000</td>\n",
              "      <td>8138.620000</td>\n",
              "      <td>8.419500</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.060000</td>\n",
              "      <td>23.419000</td>\n",
              "      <td>191</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.931457</td>\n",
              "      <td>1590.416026</td>\n",
              "      <td>1401.457881</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.153974</td>\n",
              "      <td>2388.053245</td>\n",
              "      <td>9045.473974</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.476755</td>\n",
              "      <td>521.869404</td>\n",
              "      <td>2388.036887</td>\n",
              "      <td>8136.211854</td>\n",
              "      <td>8.423654</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.039735</td>\n",
              "      <td>23.420554</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000977</td>\n",
              "      <td>-0.000194</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.039450</td>\n",
              "      <td>1589.790059</td>\n",
              "      <td>1402.165407</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.181331</td>\n",
              "      <td>2388.060148</td>\n",
              "      <td>9047.400370</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.423408</td>\n",
              "      <td>522.011470</td>\n",
              "      <td>2388.035110</td>\n",
              "      <td>8135.442471</td>\n",
              "      <td>8.422144</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.483957</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.016581</td>\n",
              "      <td>23.400853</td>\n",
              "      <td>189</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.000623</td>\n",
              "      <td>-0.000153</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.105091</td>\n",
              "      <td>1588.310457</td>\n",
              "      <td>1402.102967</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.238119</td>\n",
              "      <td>2388.070686</td>\n",
              "      <td>9047.839942</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.361390</td>\n",
              "      <td>522.190824</td>\n",
              "      <td>2388.044599</td>\n",
              "      <td>8135.101643</td>\n",
              "      <td>8.410742</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.593033</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.987712</td>\n",
              "      <td>23.395156</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.000854</td>\n",
              "      <td>-0.000162</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.153105</td>\n",
              "      <td>1587.320764</td>\n",
              "      <td>1402.849168</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.194961</td>\n",
              "      <td>2388.068749</td>\n",
              "      <td>9049.164870</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.346638</td>\n",
              "      <td>522.190674</td>\n",
              "      <td>2388.043765</td>\n",
              "      <td>8134.865724</td>\n",
              "      <td>8.414123</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391.848042</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.971815</td>\n",
              "      <td>23.396831</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...        s21  RUL  label1  label2\n",
              "0   1      1 -0.000700 -0.000400  ...  23.419000  191       0       0\n",
              "1   1      2  0.000178 -0.000366  ...  23.420554  190       0       0\n",
              "2   1      3 -0.000977 -0.000194  ...  23.400853  189       0       0\n",
              "3   1      4 -0.000623 -0.000153  ...  23.395156  188       0       0\n",
              "4   1      5 -0.000854 -0.000162  ...  23.396831  187       0       0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odG1YBVcV2cs",
        "colab_type": "text"
      },
      "source": [
        "## Normalize Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw1c_mNWV2cu",
        "colab_type": "code",
        "outputId": "8787e1f9-2f58-4cee-f535-8435a622fc17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# MinMax normalization\n",
        "train_df['cycle_norm'] = train_df['cycle']\n",
        "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
        "                             columns=cols_normalize, \n",
        "                             index=train_df.index)\n",
        "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train_df = join_df.reindex(columns = train_df.columns)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>RUL</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "      <th>cycle_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.368542</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.349894</td>\n",
              "      <td>0.185846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.878722</td>\n",
              "      <td>0.242639</td>\n",
              "      <td>0.091191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.356551</td>\n",
              "      <td>0.685441</td>\n",
              "      <td>0.131931</td>\n",
              "      <td>0.207883</td>\n",
              "      <td>0.265399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.938255</td>\n",
              "      <td>0.901462</td>\n",
              "      <td>191</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.606362</td>\n",
              "      <td>0.045503</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058599</td>\n",
              "      <td>0.381941</td>\n",
              "      <td>0.211315</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.818707</td>\n",
              "      <td>0.220732</td>\n",
              "      <td>0.086909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.363140</td>\n",
              "      <td>0.757866</td>\n",
              "      <td>0.184063</td>\n",
              "      <td>0.191990</td>\n",
              "      <td>0.295538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.907757</td>\n",
              "      <td>0.905421</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.293440</td>\n",
              "      <td>0.277092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.115377</td>\n",
              "      <td>0.353925</td>\n",
              "      <td>0.232320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.826676</td>\n",
              "      <td>0.243121</td>\n",
              "      <td>0.098430</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.311104</td>\n",
              "      <td>0.807002</td>\n",
              "      <td>0.178577</td>\n",
              "      <td>0.186913</td>\n",
              "      <td>0.284579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.092264</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872911</td>\n",
              "      <td>0.855227</td>\n",
              "      <td>189</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.389455</td>\n",
              "      <td>0.332429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149888</td>\n",
              "      <td>0.287703</td>\n",
              "      <td>0.230467</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.843218</td>\n",
              "      <td>0.277295</td>\n",
              "      <td>0.101059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250610</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>0.207868</td>\n",
              "      <td>0.184663</td>\n",
              "      <td>0.201857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829464</td>\n",
              "      <td>0.840712</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.326762</td>\n",
              "      <td>0.321014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.175131</td>\n",
              "      <td>0.243408</td>\n",
              "      <td>0.252620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.830646</td>\n",
              "      <td>0.271014</td>\n",
              "      <td>0.108983</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.236221</td>\n",
              "      <td>0.868982</td>\n",
              "      <td>0.205295</td>\n",
              "      <td>0.183106</td>\n",
              "      <td>0.226392</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157660</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.805538</td>\n",
              "      <td>0.844981</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.01108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...  RUL  label1  label2  cycle_norm\n",
              "0   1      1  0.368542  0.000000  ...  191       0       0     0.00000\n",
              "1   1      2  0.606362  0.045503  ...  190       0       0     0.00277\n",
              "2   1      3  0.293440  0.277092  ...  189       0       0     0.00554\n",
              "3   1      4  0.389455  0.332429  ...  188       0       0     0.00831\n",
              "4   1      5  0.326762  0.321014  ...  187       0       0     0.01108\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFPte0CSV2cy",
        "colab_type": "code",
        "outputId": "45c1db51-29f7-41a3-c793-4acf1edebbad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_df['cycle_norm'] = test_df['cycle']\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
        "                            columns=cols_normalize, \n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>cycle_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.181006</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.630905</td>\n",
              "      <td>0.152518</td>\n",
              "      <td>0.114891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.744724</td>\n",
              "      <td>0.177775</td>\n",
              "      <td>0.114995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093186</td>\n",
              "      <td>0.706193</td>\n",
              "      <td>0.162801</td>\n",
              "      <td>0.121627</td>\n",
              "      <td>0.161653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.637261</td>\n",
              "      <td>0.785538</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.723659</td>\n",
              "      <td>0.670047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.398285</td>\n",
              "      <td>0.200286</td>\n",
              "      <td>0.086915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.838191</td>\n",
              "      <td>0.144913</td>\n",
              "      <td>0.123580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.192020</td>\n",
              "      <td>0.757592</td>\n",
              "      <td>0.194081</td>\n",
              "      <td>0.152988</td>\n",
              "      <td>0.100639</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.245620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.718589</td>\n",
              "      <td>0.801113</td>\n",
              "      <td>0.00277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.701909</td>\n",
              "      <td>0.670968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.382339</td>\n",
              "      <td>0.207015</td>\n",
              "      <td>0.118110</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829858</td>\n",
              "      <td>0.161760</td>\n",
              "      <td>0.131843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.242023</td>\n",
              "      <td>0.766640</td>\n",
              "      <td>0.186010</td>\n",
              "      <td>0.152644</td>\n",
              "      <td>0.189200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783034</td>\n",
              "      <td>0.825428</td>\n",
              "      <td>0.00554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.911938</td>\n",
              "      <td>0.643051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.370424</td>\n",
              "      <td>0.184428</td>\n",
              "      <td>0.168949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.822331</td>\n",
              "      <td>0.158290</td>\n",
              "      <td>0.122113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227058</td>\n",
              "      <td>0.729007</td>\n",
              "      <td>0.194155</td>\n",
              "      <td>0.156341</td>\n",
              "      <td>0.162675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.219036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.796756</td>\n",
              "      <td>0.817104</td>\n",
              "      <td>0.00831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.916529</td>\n",
              "      <td>0.624173</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369036</td>\n",
              "      <td>0.194057</td>\n",
              "      <td>0.179114</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.821992</td>\n",
              "      <td>0.144187</td>\n",
              "      <td>0.114730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222241</td>\n",
              "      <td>0.751828</td>\n",
              "      <td>0.188472</td>\n",
              "      <td>0.154822</td>\n",
              "      <td>0.159729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147749</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803308</td>\n",
              "      <td>0.829623</td>\n",
              "      <td>0.01108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...  s19       s20       s21  cycle_norm\n",
              "0   1      1  1.181006  0.943062  ...  0.0  0.637261  0.785538     0.00000\n",
              "1   1      2  0.723659  0.670047  ...  0.0  0.718589  0.801113     0.00277\n",
              "2   1      3  0.701909  0.670968  ...  0.0  0.783034  0.825428     0.00554\n",
              "3   1      4  0.911938  0.643051  ...  0.0  0.796756  0.817104     0.00831\n",
              "4   1      5  0.916529  0.624173  ...  0.0  0.803308  0.829623     0.01108\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbkvYNvhV2c4",
        "colab_type": "text"
      },
      "source": [
        "## Generate True Labels (RUL) for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1QAjldiV2c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate column max for test data\n",
        "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "truth_df.columns = ['more']\n",
        "truth_df['id'] = truth_df.index + 1\n",
        "truth_df['max'] = rul['max'] + truth_df['more']\n",
        "truth_df.drop('more', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_34qXVWV2c-",
        "colab_type": "code",
        "outputId": "352dffee-0a4b-4a27-83e8-7d601e8a8d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate RUL for test data\n",
        "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
        "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
        "test_df.drop('max', axis=1, inplace=True)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>cycle_norm</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.181006</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.630905</td>\n",
              "      <td>0.152518</td>\n",
              "      <td>0.114891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.744724</td>\n",
              "      <td>0.177775</td>\n",
              "      <td>0.114995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093186</td>\n",
              "      <td>0.706193</td>\n",
              "      <td>0.162801</td>\n",
              "      <td>0.121627</td>\n",
              "      <td>0.161653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.637261</td>\n",
              "      <td>0.785538</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.723659</td>\n",
              "      <td>0.670047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.398285</td>\n",
              "      <td>0.200286</td>\n",
              "      <td>0.086915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.838191</td>\n",
              "      <td>0.144913</td>\n",
              "      <td>0.123580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.192020</td>\n",
              "      <td>0.757592</td>\n",
              "      <td>0.194081</td>\n",
              "      <td>0.152988</td>\n",
              "      <td>0.100639</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.245620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.718589</td>\n",
              "      <td>0.801113</td>\n",
              "      <td>0.00277</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.701909</td>\n",
              "      <td>0.670968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.382339</td>\n",
              "      <td>0.207015</td>\n",
              "      <td>0.118110</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829858</td>\n",
              "      <td>0.161760</td>\n",
              "      <td>0.131843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.242023</td>\n",
              "      <td>0.766640</td>\n",
              "      <td>0.186010</td>\n",
              "      <td>0.152644</td>\n",
              "      <td>0.189200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783034</td>\n",
              "      <td>0.825428</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.911938</td>\n",
              "      <td>0.643051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.370424</td>\n",
              "      <td>0.184428</td>\n",
              "      <td>0.168949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.822331</td>\n",
              "      <td>0.158290</td>\n",
              "      <td>0.122113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227058</td>\n",
              "      <td>0.729007</td>\n",
              "      <td>0.194155</td>\n",
              "      <td>0.156341</td>\n",
              "      <td>0.162675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.219036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.796756</td>\n",
              "      <td>0.817104</td>\n",
              "      <td>0.00831</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.916529</td>\n",
              "      <td>0.624173</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369036</td>\n",
              "      <td>0.194057</td>\n",
              "      <td>0.179114</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.821992</td>\n",
              "      <td>0.144187</td>\n",
              "      <td>0.114730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222241</td>\n",
              "      <td>0.751828</td>\n",
              "      <td>0.188472</td>\n",
              "      <td>0.154822</td>\n",
              "      <td>0.159729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147749</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803308</td>\n",
              "      <td>0.829623</td>\n",
              "      <td>0.01108</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...       s20       s21  cycle_norm  RUL\n",
              "0   1      1  1.181006  0.943062  ...  0.637261  0.785538     0.00000  142\n",
              "1   1      2  0.723659  0.670047  ...  0.718589  0.801113     0.00277  141\n",
              "2   1      3  0.701909  0.670968  ...  0.783034  0.825428     0.00554  140\n",
              "3   1      4  0.911938  0.643051  ...  0.796756  0.817104     0.00831  139\n",
              "4   1      5  0.916529  0.624173  ...  0.803308  0.829623     0.01108  138\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpm6fBnMV2dD",
        "colab_type": "code",
        "outputId": "e2dfe8eb-9fc2-4e06-8f49-110ffc717218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate label columns w0 and w1 for test data\n",
        "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
        "test_df['label2'] = test_df['label1']\n",
        "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>cycle_norm</th>\n",
              "      <th>RUL</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.181006</td>\n",
              "      <td>0.943062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.630905</td>\n",
              "      <td>0.152518</td>\n",
              "      <td>0.114891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.744724</td>\n",
              "      <td>0.177775</td>\n",
              "      <td>0.114995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.093186</td>\n",
              "      <td>0.706193</td>\n",
              "      <td>0.162801</td>\n",
              "      <td>0.121627</td>\n",
              "      <td>0.161653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.637261</td>\n",
              "      <td>0.785538</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>142</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.723659</td>\n",
              "      <td>0.670047</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.398285</td>\n",
              "      <td>0.200286</td>\n",
              "      <td>0.086915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.838191</td>\n",
              "      <td>0.144913</td>\n",
              "      <td>0.123580</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.192020</td>\n",
              "      <td>0.757592</td>\n",
              "      <td>0.194081</td>\n",
              "      <td>0.152988</td>\n",
              "      <td>0.100639</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.245620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.718589</td>\n",
              "      <td>0.801113</td>\n",
              "      <td>0.00277</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.701909</td>\n",
              "      <td>0.670968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.382339</td>\n",
              "      <td>0.207015</td>\n",
              "      <td>0.118110</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829858</td>\n",
              "      <td>0.161760</td>\n",
              "      <td>0.131843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.242023</td>\n",
              "      <td>0.766640</td>\n",
              "      <td>0.186010</td>\n",
              "      <td>0.152644</td>\n",
              "      <td>0.189200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783034</td>\n",
              "      <td>0.825428</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.911938</td>\n",
              "      <td>0.643051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.370424</td>\n",
              "      <td>0.184428</td>\n",
              "      <td>0.168949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.822331</td>\n",
              "      <td>0.158290</td>\n",
              "      <td>0.122113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227058</td>\n",
              "      <td>0.729007</td>\n",
              "      <td>0.194155</td>\n",
              "      <td>0.156341</td>\n",
              "      <td>0.162675</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.219036</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.796756</td>\n",
              "      <td>0.817104</td>\n",
              "      <td>0.00831</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.916529</td>\n",
              "      <td>0.624173</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369036</td>\n",
              "      <td>0.194057</td>\n",
              "      <td>0.179114</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.821992</td>\n",
              "      <td>0.144187</td>\n",
              "      <td>0.114730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222241</td>\n",
              "      <td>0.751828</td>\n",
              "      <td>0.188472</td>\n",
              "      <td>0.154822</td>\n",
              "      <td>0.159729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.147749</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803308</td>\n",
              "      <td>0.829623</td>\n",
              "      <td>0.01108</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...  cycle_norm  RUL  label1  label2\n",
              "0   1      1  1.181006  0.943062  ...     0.00000  142       0       0\n",
              "1   1      2  0.723659  0.670047  ...     0.00277  141       0       0\n",
              "2   1      3  0.701909  0.670968  ...     0.00554  140       0       0\n",
              "3   1      4  0.911938  0.643051  ...     0.00831  139       0       0\n",
              "4   1      5  0.916529  0.624173  ...     0.01108  138       0       0\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLT-yQglV2dH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.drop(['label1','label2'],axis=1,inplace=True)\n",
        "test_df.drop(['label1','label2'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYVAxTAlV2dN",
        "colab_type": "code",
        "outputId": "20cfa495-5731-48bd-b5cc-7b5dc8d15577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cols = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', \n",
        "        's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21', 'cycle_norm']\n",
        "len(cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5PwOohtV2dS",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru1qtRszV2dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras import Model\n",
        "from keras import regularizers, optimizers, activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhPcZErWV2dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(cols)\n",
        "encoding_dim = 14\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
        "\n",
        "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='relu')(decoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "587_yWE3V2db",
        "colab_type": "code",
        "outputId": "717ba286-9c7c-40d2-fa34-cdd2f746f3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = pd.concat([train_df[cols], test_df[cols]])\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33727, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz_zKHYUV2df",
        "colab_type": "text"
      },
      "source": [
        "## Train the Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o4XAggRV2dg",
        "colab_type": "code",
        "outputId": "08431a6d-b877-466c-dfa7-28c25ec9b286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 32\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy', 'mse'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"autoenc_rul_model.h5\", verbose=0, save_best_only=True)\n",
        "\n",
        "history = autoencoder.fit(data, data, epochs=nb_epoch, batch_size=batch_size, shuffle=True,\n",
        "                    validation_split=0.15, verbose=1, callbacks=[checkpointer]).history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28667 samples, validate on 5060 samples\n",
            "Epoch 1/100\n",
            "28667/28667 [==============================] - 4s 125us/step - loss: 0.0486 - acc: 0.8335 - mean_squared_error: 0.0430 - val_loss: 0.0352 - val_acc: 0.8656 - val_mean_squared_error: 0.0335\n",
            "Epoch 2/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0389 - acc: 0.8545 - mean_squared_error: 0.0374 - val_loss: 0.0342 - val_acc: 0.8791 - val_mean_squared_error: 0.0331\n",
            "Epoch 3/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0379 - acc: 0.8654 - mean_squared_error: 0.0368 - val_loss: 0.0336 - val_acc: 0.8893 - val_mean_squared_error: 0.0326\n",
            "Epoch 4/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0371 - acc: 0.8724 - mean_squared_error: 0.0361 - val_loss: 0.0329 - val_acc: 0.8927 - val_mean_squared_error: 0.0320\n",
            "Epoch 5/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0364 - acc: 0.8872 - mean_squared_error: 0.0356 - val_loss: 0.0326 - val_acc: 0.9099 - val_mean_squared_error: 0.0319\n",
            "Epoch 6/100\n",
            "28667/28667 [==============================] - 3s 113us/step - loss: 0.0361 - acc: 0.8989 - mean_squared_error: 0.0354 - val_loss: 0.0324 - val_acc: 0.9138 - val_mean_squared_error: 0.0318\n",
            "Epoch 7/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0360 - acc: 0.8989 - mean_squared_error: 0.0353 - val_loss: 0.0322 - val_acc: 0.9103 - val_mean_squared_error: 0.0317\n",
            "Epoch 8/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0358 - acc: 0.8991 - mean_squared_error: 0.0352 - val_loss: 0.0320 - val_acc: 0.9138 - val_mean_squared_error: 0.0315\n",
            "Epoch 9/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0341 - acc: 0.9061 - mean_squared_error: 0.0336 - val_loss: 0.0268 - val_acc: 0.9184 - val_mean_squared_error: 0.0263\n",
            "Epoch 10/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0276 - acc: 0.9128 - mean_squared_error: 0.0271 - val_loss: 0.0266 - val_acc: 0.9257 - val_mean_squared_error: 0.0262\n",
            "Epoch 11/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0275 - acc: 0.9160 - mean_squared_error: 0.0270 - val_loss: 0.0266 - val_acc: 0.9269 - val_mean_squared_error: 0.0261\n",
            "Epoch 12/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0274 - acc: 0.9169 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9277 - val_mean_squared_error: 0.0261\n",
            "Epoch 13/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0274 - acc: 0.9173 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9289 - val_mean_squared_error: 0.0261\n",
            "Epoch 14/100\n",
            "28667/28667 [==============================] - 3s 112us/step - loss: 0.0274 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n",
            "Epoch 15/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0274 - acc: 0.9182 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9292 - val_mean_squared_error: 0.0261\n",
            "Epoch 16/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0274 - acc: 0.9179 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9296 - val_mean_squared_error: 0.0261\n",
            "Epoch 17/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0273 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9285 - val_mean_squared_error: 0.0262\n",
            "Epoch 18/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0273 - acc: 0.9179 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9287 - val_mean_squared_error: 0.0261\n",
            "Epoch 19/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0273 - acc: 0.9177 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9296 - val_mean_squared_error: 0.0262\n",
            "Epoch 20/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0273 - acc: 0.9172 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9281 - val_mean_squared_error: 0.0262\n",
            "Epoch 21/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0273 - acc: 0.9185 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9304 - val_mean_squared_error: 0.0261\n",
            "Epoch 22/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0273 - acc: 0.9182 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n",
            "Epoch 23/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0273 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9300 - val_mean_squared_error: 0.0261\n",
            "Epoch 24/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0273 - acc: 0.9184 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9275 - val_mean_squared_error: 0.0261\n",
            "Epoch 25/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0273 - acc: 0.9179 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n",
            "Epoch 26/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0273 - acc: 0.9180 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9306 - val_mean_squared_error: 0.0261\n",
            "Epoch 27/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0273 - acc: 0.9184 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9292 - val_mean_squared_error: 0.0261\n",
            "Epoch 28/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0273 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9304 - val_mean_squared_error: 0.0261\n",
            "Epoch 29/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0273 - acc: 0.9177 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9300 - val_mean_squared_error: 0.0261\n",
            "Epoch 30/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0273 - acc: 0.9182 - mean_squared_error: 0.0270 - val_loss: 0.0265 - val_acc: 0.9231 - val_mean_squared_error: 0.0263\n",
            "Epoch 31/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0273 - acc: 0.9179 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9287 - val_mean_squared_error: 0.0261\n",
            "Epoch 32/100\n",
            "28667/28667 [==============================] - 3s 113us/step - loss: 0.0272 - acc: 0.9182 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9283 - val_mean_squared_error: 0.0261\n",
            "Epoch 33/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0272 - acc: 0.9173 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9289 - val_mean_squared_error: 0.0261\n",
            "Epoch 34/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9302 - val_mean_squared_error: 0.0261\n",
            "Epoch 35/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0272 - acc: 0.9180 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9281 - val_mean_squared_error: 0.0261\n",
            "Epoch 36/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9300 - val_mean_squared_error: 0.0261\n",
            "Epoch 37/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9243 - val_mean_squared_error: 0.0262\n",
            "Epoch 38/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9296 - val_mean_squared_error: 0.0261\n",
            "Epoch 39/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0272 - acc: 0.9180 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9277 - val_mean_squared_error: 0.0262\n",
            "Epoch 40/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9291 - val_mean_squared_error: 0.0262\n",
            "Epoch 41/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9285 - val_mean_squared_error: 0.0262\n",
            "Epoch 42/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9275 - val_mean_squared_error: 0.0262\n",
            "Epoch 43/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0272 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9259 - val_mean_squared_error: 0.0262\n",
            "Epoch 44/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9172 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9269 - val_mean_squared_error: 0.0262\n",
            "Epoch 45/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0272 - acc: 0.9181 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9281 - val_mean_squared_error: 0.0261\n",
            "Epoch 46/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9271 - val_mean_squared_error: 0.0262\n",
            "Epoch 47/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9281 - val_mean_squared_error: 0.0262\n",
            "Epoch 48/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9292 - val_mean_squared_error: 0.0261\n",
            "Epoch 49/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9177 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9271 - val_mean_squared_error: 0.0262\n",
            "Epoch 50/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9169 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9306 - val_mean_squared_error: 0.0262\n",
            "Epoch 51/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0272 - acc: 0.9172 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9247 - val_mean_squared_error: 0.0262\n",
            "Epoch 52/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9273 - val_mean_squared_error: 0.0261\n",
            "Epoch 53/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0261\n",
            "Epoch 54/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9171 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0262\n",
            "Epoch 55/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0272 - acc: 0.9172 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9287 - val_mean_squared_error: 0.0261\n",
            "Epoch 56/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0272 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0270 - val_acc: 0.9255 - val_mean_squared_error: 0.0268\n",
            "Epoch 57/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9279 - val_mean_squared_error: 0.0261\n",
            "Epoch 58/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9281 - val_mean_squared_error: 0.0261\n",
            "Epoch 59/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9173 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0261\n",
            "Epoch 60/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9173 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0261\n",
            "Epoch 61/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0262\n",
            "Epoch 62/100\n",
            "28667/28667 [==============================] - 3s 103us/step - loss: 0.0272 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9269 - val_mean_squared_error: 0.0262\n",
            "Epoch 63/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0261\n",
            "Epoch 64/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9287 - val_mean_squared_error: 0.0261\n",
            "Epoch 65/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0272 - acc: 0.9181 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9255 - val_mean_squared_error: 0.0262\n",
            "Epoch 66/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9273 - val_mean_squared_error: 0.0262\n",
            "Epoch 67/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0272 - acc: 0.9165 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9271 - val_mean_squared_error: 0.0262\n",
            "Epoch 68/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9181 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9289 - val_mean_squared_error: 0.0261\n",
            "Epoch 69/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9168 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9289 - val_mean_squared_error: 0.0261\n",
            "Epoch 70/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9168 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9281 - val_mean_squared_error: 0.0261\n",
            "Epoch 71/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9275 - val_mean_squared_error: 0.0261\n",
            "Epoch 72/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0262\n",
            "Epoch 73/100\n",
            "28667/28667 [==============================] - 3s 108us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9298 - val_mean_squared_error: 0.0262\n",
            "Epoch 74/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0272 - acc: 0.9168 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9271 - val_mean_squared_error: 0.0261\n",
            "Epoch 75/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9296 - val_mean_squared_error: 0.0261\n",
            "Epoch 76/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n",
            "Epoch 77/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9162 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9287 - val_mean_squared_error: 0.0261\n",
            "Epoch 78/100\n",
            "28667/28667 [==============================] - 3s 104us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9296 - val_mean_squared_error: 0.0261\n",
            "Epoch 79/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0261\n",
            "Epoch 80/100\n",
            "28667/28667 [==============================] - 3s 103us/step - loss: 0.0272 - acc: 0.9164 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n",
            "Epoch 81/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9179 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n",
            "Epoch 82/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9273 - val_mean_squared_error: 0.0261\n",
            "Epoch 83/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0272 - acc: 0.9173 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9302 - val_mean_squared_error: 0.0261\n",
            "Epoch 84/100\n",
            "28667/28667 [==============================] - 3s 113us/step - loss: 0.0272 - acc: 0.9168 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9304 - val_mean_squared_error: 0.0261\n",
            "Epoch 85/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9292 - val_mean_squared_error: 0.0261\n",
            "Epoch 86/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9172 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9292 - val_mean_squared_error: 0.0261\n",
            "Epoch 87/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0272 - acc: 0.9176 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9296 - val_mean_squared_error: 0.0261\n",
            "Epoch 88/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9171 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9142 - val_mean_squared_error: 0.0263\n",
            "Epoch 89/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9177 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9277 - val_mean_squared_error: 0.0263\n",
            "Epoch 90/100\n",
            "28667/28667 [==============================] - 3s 110us/step - loss: 0.0272 - acc: 0.9181 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9291 - val_mean_squared_error: 0.0262\n",
            "Epoch 91/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0272 - acc: 0.9171 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9281 - val_mean_squared_error: 0.0261\n",
            "Epoch 92/100\n",
            "28667/28667 [==============================] - 3s 106us/step - loss: 0.0272 - acc: 0.9166 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9291 - val_mean_squared_error: 0.0261\n",
            "Epoch 93/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0271 - acc: 0.9181 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9296 - val_mean_squared_error: 0.0261\n",
            "Epoch 94/100\n",
            "28667/28667 [==============================] - 3s 111us/step - loss: 0.0272 - acc: 0.9175 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9277 - val_mean_squared_error: 0.0261\n",
            "Epoch 95/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0271 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0264 - val_acc: 0.9215 - val_mean_squared_error: 0.0262\n",
            "Epoch 96/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0271 - val_loss: 0.0263 - val_acc: 0.9292 - val_mean_squared_error: 0.0262\n",
            "Epoch 97/100\n",
            "28667/28667 [==============================] - 3s 107us/step - loss: 0.0272 - acc: 0.9174 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9304 - val_mean_squared_error: 0.0261\n",
            "Epoch 98/100\n",
            "28667/28667 [==============================] - 3s 105us/step - loss: 0.0271 - acc: 0.9178 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9300 - val_mean_squared_error: 0.0261\n",
            "Epoch 99/100\n",
            "28667/28667 [==============================] - 3s 109us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0263 - val_acc: 0.9263 - val_mean_squared_error: 0.0262\n",
            "Epoch 100/100\n",
            "28667/28667 [==============================] - 3s 112us/step - loss: 0.0272 - acc: 0.9170 - mean_squared_error: 0.0270 - val_loss: 0.0262 - val_acc: 0.9294 - val_mean_squared_error: 0.0261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN-tUhi7V2dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, load_model\n",
        "autoencoder = load_model('autoenc_rul_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF2jQrtoV2do",
        "colab_type": "code",
        "outputId": "783aa0c3-49a5-4d5f-a0b8-c406aae2df9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "predictions = autoencoder.predict(data)\n",
        "feat = pd.DataFrame(predictions)\n",
        "feat.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.367734</td>\n",
              "      <td>0.111243</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.231750</td>\n",
              "      <td>0.161641</td>\n",
              "      <td>0.177416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.988763</td>\n",
              "      <td>0.823335</td>\n",
              "      <td>0.192579</td>\n",
              "      <td>0.120866</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.838129</td>\n",
              "      <td>0.208803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.183575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172723</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.815427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.597986</td>\n",
              "      <td>0.094591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.253239</td>\n",
              "      <td>0.180008</td>\n",
              "      <td>0.201949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.988076</td>\n",
              "      <td>0.800809</td>\n",
              "      <td>0.207755</td>\n",
              "      <td>0.131713</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.816612</td>\n",
              "      <td>0.223240</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.206183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.194371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.794389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.283073</td>\n",
              "      <td>0.283757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.245948</td>\n",
              "      <td>0.176026</td>\n",
              "      <td>0.193508</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.987813</td>\n",
              "      <td>0.808863</td>\n",
              "      <td>0.207236</td>\n",
              "      <td>0.121385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.822638</td>\n",
              "      <td>0.222524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.199970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184071</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.799482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.380589</td>\n",
              "      <td>0.339491</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.235709</td>\n",
              "      <td>0.160580</td>\n",
              "      <td>0.182724</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.989290</td>\n",
              "      <td>0.815900</td>\n",
              "      <td>0.212145</td>\n",
              "      <td>0.099778</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829400</td>\n",
              "      <td>0.227189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.187921</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.168029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.810915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.318169</td>\n",
              "      <td>0.327582</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.247332</td>\n",
              "      <td>0.175219</td>\n",
              "      <td>0.195529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.990162</td>\n",
              "      <td>0.805729</td>\n",
              "      <td>0.214409</td>\n",
              "      <td>0.113440</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.819215</td>\n",
              "      <td>0.229381</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.201294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.182914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.798042</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1    2    3         4   ...   20   21        22   23        24\n",
              "0  0.367734  0.111243  0.0  0.0  0.231750  ...  0.0  0.0  0.815427  0.0  0.015382\n",
              "1  0.597986  0.094591  0.0  0.0  0.253239  ...  0.0  0.0  0.794389  0.0  0.007314\n",
              "2  0.283073  0.283757  0.0  0.0  0.245948  ...  0.0  0.0  0.799482  0.0  0.001823\n",
              "3  0.380589  0.339491  0.0  0.0  0.235709  ...  0.0  0.0  0.810915  0.0  0.003340\n",
              "4  0.318169  0.327582  0.0  0.0  0.247332  ...  0.0  0.0  0.798042  0.0  0.006215\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvOFk8NMV2dt",
        "colab_type": "text"
      },
      "source": [
        "## Get the Activations at the Output of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWvtfSU3V2du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(cols)\n",
        "encoding_dim = 14\n",
        "\n",
        "input_l = Input(shape=(input_dim, ))\n",
        "\n",
        "enc = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_l)\n",
        "enc = Dense(int(encoding_dim / 2), activation=\"relu\")(enc)\n",
        "\n",
        "encod = Model(inputs=input_l, outputs=enc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzvEkeb-V2dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encod.set_weights(autoencoder.layers[0].get_weights())\n",
        "\n",
        "encod.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGoxyko1V2d1",
        "colab_type": "code",
        "outputId": "b2d82fce-7f64-4f28-ed2d-d922efaa053b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "encod.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 14)                364       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 7)                 105       \n",
            "=================================================================\n",
            "Total params: 469\n",
            "Trainable params: 469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmKqV273V2d5",
        "colab_type": "code",
        "outputId": "42c11950-1e60-44f8-9bdb-594dc6d96ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_act = encod.predict(train_df[cols], verbose=1)\n",
        "test_act = encod.predict(test_df[cols], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20631/20631 [==============================] - 1s 32us/step\n",
            "13096/13096 [==============================] - 0s 22us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTisJRpPV2d8",
        "colab_type": "code",
        "outputId": "0b57bb5c-4817-4a05-ff2b-3493e29011a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "train_act_df = pd.DataFrame(train_act)\n",
        "test_act_df = pd.DataFrame(test_act)\n",
        "train_act_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.577386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137588</td>\n",
              "      <td>0.695363</td>\n",
              "      <td>0.993560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.556812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060657</td>\n",
              "      <td>0.652261</td>\n",
              "      <td>1.010713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.562286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.197591</td>\n",
              "      <td>0.712470</td>\n",
              "      <td>0.965784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.570767</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.199277</td>\n",
              "      <td>0.744735</td>\n",
              "      <td>1.005440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.561180</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.218605</td>\n",
              "      <td>0.738037</td>\n",
              "      <td>1.049752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1         2    3         4         5         6\n",
              "0  0.0  0.0  0.577386  0.0  0.137588  0.695363  0.993560\n",
              "1  0.0  0.0  0.556812  0.0  0.060657  0.652261  1.010713\n",
              "2  0.0  0.0  0.562286  0.0  0.197591  0.712470  0.965784\n",
              "3  0.0  0.0  0.570767  0.0  0.199277  0.744735  1.005440\n",
              "4  0.0  0.0  0.561180  0.0  0.218605  0.738037  1.049752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpssUDggV2d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_act_df['RUL'] = train_df['RUL']\n",
        "test_act_df['RUL'] = test_df['RUL']\n",
        "train_act_df['id'] = train_df['id']\n",
        "test_act_df['id'] = test_df['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17QEkW2eV2eC",
        "colab_type": "code",
        "outputId": "58e3d7f0-5dcd-4803-97ac-1cc2ef450446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "train.columns = cols\n",
        "test.columns = cols"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-70669143ee44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZGTcvO2V2eF",
        "colab_type": "code",
        "outputId": "ad2be08d-592e-44fb-806d-9228ba381cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "train['RUL'] = train_df['RUL']\n",
        "test['RUL'] = test_df['RUL']\n",
        "train['id'] = train_df['id']\n",
        "test['id'] = test_df['id']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-d986baebbafa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RUL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RUL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RUL'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RUL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb3RF3cAV2eJ",
        "colab_type": "text"
      },
      "source": [
        "## Train and Test Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC6gvieHV2eK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pick a large window size of 50 cycles\n",
        "sequence_length = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsXQV098V2eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to reshape features into (samples, time steps, features) \n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_array[start:stop, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWvCAKU3V2eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pick the feature columns \n",
        "sensor_cols = [i for i in range(0,20)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0VsA0hwV2eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pick the feature columns \n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
        "sequence_cols.extend(sensor_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdKQ-R5dV2eZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sensor_cols = [0, 1, 2, 3, 4, 5, 6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CfGFlsFV2ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator for the sequences\n",
        "seq_gen = (list(gen_sequence(train_act_df[train_act_df['id']==id], sequence_length, sensor_cols)) \n",
        "           for id in train_act_df['id'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viW1eu03V2ei",
        "colab_type": "code",
        "outputId": "2e553af6-6607-4370-b466-0f4faae36cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "seq_array.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15631, 50, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HexLarvuV2em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length:num_elements, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9qt3xSrV2eq",
        "colab_type": "code",
        "outputId": "a225a935-01d5-4c18-8e12-fed3deb942e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generate labels\n",
        "label_gen = [gen_labels(train_act_df[train_act_df['id']==id], sequence_length, ['RUL']) \n",
        "             for id in train_act_df['id'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "label_array.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15631, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBSEWrdEV2et",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFcHWA9cV2ev",
        "colab_type": "code",
        "outputId": "9528eae0-1134-4651-a3df-cbbbeadaab96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# build the network\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "         units=100,\n",
        "         return_sequences=True,\n",
        "         input_shape=(sequence_length, nb_features)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(units=1, activation='relu'))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uafgdIDdV2fA",
        "colab_type": "code",
        "outputId": "c086eb0a-fa60-46bc-e1ed-c17f9869fe37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 50, 100)           43200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 51        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 73,451\n",
            "Trainable params: 73,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4tn4fg4V2fD",
        "colab_type": "text"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y3hzSv0V2fE",
        "colab_type": "code",
        "outputId": "466c2408-e3af-4ce1-8d17-e13634e23515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "STAMP = 'predictive_regression_kalhman'\n",
        "print(STAMP)\n",
        "\n",
        "early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
        "bst_model_path = STAMP + '.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictive_regression_kalhman\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZEktDK1V2fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=RMSprop(lr=1e-2), metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQ0zS9JV2fK",
        "colab_type": "code",
        "outputId": "7d3992ec-5491-4a97-9e4c-d3aff5253a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "%%time\n",
        "# fit the network\n",
        "hist = model.fit(seq_array, label_array, epochs=10, batch_size=200, validation_split=0.05, verbose=1,callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 14849 samples, validate on 782 samples\n",
            "Epoch 1/10\n",
            "14849/14849 [==============================] - 12s 815us/step - loss: 6993.6019 - mean_squared_error: 6993.6019 - val_loss: 5121.3855 - val_mean_squared_error: 5121.3855\n",
            "Epoch 2/10\n",
            "14849/14849 [==============================] - 11s 713us/step - loss: 4325.9255 - mean_squared_error: 4325.9255 - val_loss: 3452.9651 - val_mean_squared_error: 3452.9651\n",
            "Epoch 3/10\n",
            "14849/14849 [==============================] - 11s 731us/step - loss: 3440.9262 - mean_squared_error: 3440.9262 - val_loss: 3168.7608 - val_mean_squared_error: 3168.7608\n",
            "Epoch 4/10\n",
            "14849/14849 [==============================] - 11s 717us/step - loss: 3399.5373 - mean_squared_error: 3399.5373 - val_loss: 3169.8808 - val_mean_squared_error: 3169.8808\n",
            "Epoch 5/10\n",
            "14849/14849 [==============================] - 11s 711us/step - loss: 3391.5144 - mean_squared_error: 3391.5144 - val_loss: 3169.8265 - val_mean_squared_error: 3169.8265\n",
            "Epoch 6/10\n",
            "14849/14849 [==============================] - 11s 725us/step - loss: 3390.1820 - mean_squared_error: 3390.1820 - val_loss: 3169.2126 - val_mean_squared_error: 3169.2126\n",
            "Epoch 7/10\n",
            "14849/14849 [==============================] - 11s 716us/step - loss: 3379.3549 - mean_squared_error: 3379.3549 - val_loss: 3197.1026 - val_mean_squared_error: 3197.1026\n",
            "Epoch 8/10\n",
            "14849/14849 [==============================] - 11s 712us/step - loss: 2642.1011 - mean_squared_error: 2642.1011 - val_loss: 1573.0018 - val_mean_squared_error: 1573.0018\n",
            "Epoch 9/10\n",
            "14849/14849 [==============================] - 11s 724us/step - loss: 1821.6567 - mean_squared_error: 1821.6567 - val_loss: 1602.2866 - val_mean_squared_error: 1602.2866\n",
            "Epoch 10/10\n",
            "14849/14849 [==============================] - 11s 713us/step - loss: 1426.3579 - mean_squared_error: 1426.3579 - val_loss: 3984.9529 - val_mean_squared_error: 3984.9529\n",
            "CPU times: user 2min 29s, sys: 7.96 s, total: 2min 37s\n",
            "Wall time: 1min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeYCF7S4V2fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(bst_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "XtN0OPhDV2fR",
        "colab_type": "code",
        "outputId": "3b96993b-6252-4c77-adb4-268b4b0c1976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# training metrics\n",
        "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
        "print('Score: {}'.format(scores[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15631/15631 [==============================] - 4s 279us/step\n",
            "Score: 1780.9274901338276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE73Az6uV2fV",
        "colab_type": "code",
        "outputId": "6e05df84-a7f7-4392-dc7e-fe72581528de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "p = pd.DataFrame(np.zeros((1, 25)), columns=cols)\n",
        "test = pd.concat([test, p])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-1d5eff675bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcZLGdkmV2fY",
        "colab_type": "code",
        "outputId": "1eeda20f-7a72-4543-c717-e33061f21526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_array_test_last = [test_act_df[test_act_df['id']==id][sensor_cols].values[-sequence_length:] \n",
        "                       for id in test_act_df['id'].unique() if len(test_act_df[test_act_df['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "seq_array_test_last.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93, 50, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT78N-PCV2fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_mask = [len(test_act_df[test_act_df['id']==id]) >= sequence_length for id in test_act_df['id'].unique()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHb82UWnV2fh",
        "colab_type": "code",
        "outputId": "b2dc488e-9974-431a-952a-f6b35c5d2e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_array_test_last = test_act_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
        "label_array_test_last.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t87NSCuKV2fk",
        "colab_type": "code",
        "outputId": "323d9b74-aa93-4583-c451-0601d7fe2abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(seq_array_test_last.shape)\n",
        "print(label_array_test_last.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(93, 50, 7)\n",
            "(93, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bep-wONQV2fo",
        "colab_type": "text"
      },
      "source": [
        "## Results on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S65X1pRwV2fo",
        "colab_type": "code",
        "outputId": "e141cd04-27c3-48e5-8ac8-f2d01b326d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test metrics\n",
        "import math\n",
        "scores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)' % (scores_test[0], math.sqrt(scores_test[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score: 572.78 MSE (23.93 RMSE)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt9j0HUtV2fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(seq_array_test_last)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Lb1_BJV2ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diff = []\n",
        "ratio = []\n",
        "pred = model.predict(seq_array_test_last)\n",
        "for u in range(len(label_array_test_last)):\n",
        "    pr = pred[u][0]\n",
        "    ratio.append((label_array_test_last[u] / pr) - 1)\n",
        "    diff.append(abs(label_array_test_last[u] - pr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrcvxa8EV2fw",
        "colab_type": "text"
      },
      "source": [
        "## Plot of Predicted and True RUL Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md4gFxaKV2fx",
        "colab_type": "code",
        "outputId": "4419655c-43be-4971-8e16-c0820af08699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "plt2.plot(pred, color='red', label='Prediction')\n",
        "plt2.plot(label_array_test_last, color='blue', label='Ground Truth')\n",
        "plt2.legend(loc='upper left')\n",
        "plt2.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+vHYn6AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-rxd3b1V2fz",
        "colab_type": "code",
        "outputId": "a5baba4b-a21b-4d4d-aaa7-5fd928e1979c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "error = pd.DataFrame(( label_array_test_last - pred),columns=['error'])\n",
        "error.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>93.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.720670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>24.000359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-47.447212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-12.306889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-1.070902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.288216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.169930</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           error\n",
              "count  93.000000\n",
              "mean    1.720670\n",
              "std    24.000359\n",
              "min   -47.447212\n",
              "25%   -12.306889\n",
              "50%    -1.070902\n",
              "75%    15.288216\n",
              "max    60.169930"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwhJ5IN8V2f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}